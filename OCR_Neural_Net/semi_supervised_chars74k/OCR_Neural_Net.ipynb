{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \t The Chars74K dataset\n",
    "\n",
    "# OCR\n",
    "\n",
    "## Department of Electrical and Computer Engineering, University of Thessaly, Volos, Greece\n",
    "\n",
    "## Project: IoT OCR Part5\n",
    "---\n",
    "\n",
    "In this project, we implement a solution about is the [Chars74k](http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/). Character recognition is a classic pattern recognition problem.The recognition is for latin letters and digits.\n",
    "> **Note**: 62 classes (0-9, A-Z, a-z)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction \n",
    "<img src=\"download.png\"> \n",
    "\n",
    "\n",
    "- **STEP 1** is a pre-processing step where we prepareoy data to be fed in the NN.\n",
    "\n",
    "- **STEP 2** is the Encoder step that takes the picture and converts it into D-dimensional tensor with L-Features with a CNN.This also cold feature extraction step because it detects patterns to help the detection process.\n",
    "- **STEP 3** is the decoder which accepts the Encoder output as input and returns a probability distribution over all the classes with a  DNN(deep neural network) .\n",
    "\n",
    "## The Data\n",
    "The Chars74k dataset consists of:\n",
    "\n",
    "- Image size: 64x64 or 128X128\n",
    "- 7705 characters obtained from natural images\n",
    "- 3410 hand drawn characters using a tablet PC\n",
    "- 62992 synthesised characters from computer font\n",
    "\n",
    "\n",
    "## Requirements\n",
    "- python3\n",
    "- Tansorflow 1.12 gpu\n",
    "- opencv\n",
    "- At least 16GB RAM\n",
    "- At least 3GB GPU RAM\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Example!\n",
    "<img src=\"unnamed.png\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theologis\\Desktop\\CAS Lab\\sem-supervised_chars74k\n"
     ]
    }
   ],
   "source": [
    "proj_directory = '/Users/Theologis/Desktop/CAS Lab/sem-supervised_chars74k/' ##TOCHANGE...\n",
    "%cd $proj_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1 \n",
    "  At this step we load every image. We also  randomly shuffle data to train,validate and test sets and then plot a radom image for visualisation  purposes .The output of the NN should be a one hot encoded vector.This vector must have 1 in the right class and 0 the other 62 classes.\n",
    "### Improving performance\n",
    "The dataset is quite small (less than 10K images). Data augmentation along with a  [GAN](https://www.tensorflow.org/tutorials/generative/dcgan) model help as increase our model's accuracy from 70%  to $88 $% .The GAN model also add the 63th class witch gives as the probability that the image is latter in the 62 classes. \n",
    "#### Data augmentation Steps\n",
    "- Random rotations between -10 and 10 degrees.\n",
    "- Random translation between -10 and 10 pixels in any direction.\n",
    "- Random zoom between factors of 1 and 1.3.\n",
    "- Gray scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 62/62 [00:06<00:00,  9.03i/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 62/62 [00:14<00:00,  4.24i/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loades with shape :  (20, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "from data_gen import load_data\n",
    "train_x, train_y,val_x, val_y,test_x, test_y,input_shape = load_data(proj_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot Vector is: [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_x[2])\n",
    "print(\"One hot Vector is:\",train_y[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last steps (Our model)\n",
    "In semi-supervised learning, our goal is still to train a model that takes $x$ as input and generates $y$ as output. However, not all of our training examples have a label $y$. We need to develop an algorithm that is able to get better at classification by studying both labeled $(x, y)$ pairs and unlabeled $x$ examples.\n",
    "\n",
    "To do this for the Chars74K dataset, we'll turn the GAN discriminator into an 62 class discriminator. It will recognize the 10 different classes of real Chars74K, as well as an 63th class of fake images that come from the generator. The discriminator will get to train on real labeled images, real unlabeled images, and fake images. By drawing on three sources of data instead of just one, it will generalize to the test set much better than a traditional classifier trained on only one source of data.The idea of this model was form this [paper](https://arxiv.org/pdf/1606.03498.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theologis\\anaconda3\\envs\\tf-dnndk\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Theologis\\anaconda3\\envs\\tf-dnndk\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Theologis\\anaconda3\\envs\\tf-dnndk\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Theologis\\anaconda3\\envs\\tf-dnndk\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Theologis\\anaconda3\\envs\\tf-dnndk\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Theologis\\anaconda3\\envs\\tf-dnndk\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Theologis\\Desktop\\CAS Lab\\sem-supervised_chars74k\\model.py:105: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Theologis\\Desktop\\CAS Lab\\sem-supervised_chars74k\\model.py:158: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from train_utils import GAN\n",
    "\n",
    "real_size = (32,32,1)\n",
    "learning_rate = 0.001\n",
    "\n",
    "net = GAN(real_size, learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model: \"sequential_12\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d_68 (Conv2D)           (None, 15, 15, 64)        640       \n",
    "_________________________________________________________________\n",
    "conv2d_69 (Conv2D)           (None, 7, 7, 64)          36928     \n",
    "_________________________________________________________________\n",
    "batch_normalization_36 (Batc (None, 7, 7, 64)          256       \n",
    "_________________________________________________________________\n",
    "conv2d_70 (Conv2D)           (None, 3, 3, 64)          36928     \n",
    "_________________________________________________________________\n",
    "batch_normalization_37 (Batc (None, 3, 3, 64)          256       \n",
    "_________________________________________________________________\n",
    "conv2d_71 (Conv2D)           (None, 1, 1, 128)         73856     \n",
    "_________________________________________________________________\n",
    "batch_normalization_38 (Batc (None, 1, 1, 128)         512       \n",
    "_________________________________________________________________\n",
    "conv2d_72 (Conv2D)           (None, 1, 1, 128)         147584    \n",
    "_________________________________________________________________\n",
    "batch_normalization_39 (Batc (None, 1, 1, 128)         512       \n",
    "_________________________________________________________________\n",
    "conv2d_73 (Conv2D)           (None, 1, 1, 128)         147584    \n",
    "_________________________________________________________________\n",
    "flatten_10 (Flatten)         (None, 128)               0         \n",
    "_________________________________________________________________\n",
    "dense_10 (Dense)             (None, 62)                7998      \n",
    "=================================================================\n",
    "Total params: 453,054\n",
    "Trainable params: 452,286\n",
    "Non-trainable params: 768\n",
    "_________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 62/62 [00:37<00:00,  1.67i/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62992 data successfully loades with shape :  (32, 32, 1)\n",
      "Saving Test Data\n",
      "Epoch 0\n",
      "\t\tClassifier train accuracy:  0.698433524173028\n",
      "\t\tClassifier validation accuracy 0.7833227040816326\n",
      "\t\tStep time:  0.03152632713317871\n",
      "\t\tEpoch time:  15.537950038909912\n",
      "Epoch 1\n",
      "\t\tClassifier train accuracy:  0.816690853428225\n",
      "\t\tClassifier validation accuracy 0.8158482142857143\n",
      "\t\tStep time:  0.03152728080749512\n",
      "\t\tEpoch time:  12.98215937614441\n",
      "Epoch 2\n",
      "\t\tClassifier train accuracy:  0.8416197841083036\n",
      "\t\tClassifier validation accuracy 0.8391262755102041\n",
      "\t\tStep time:  0.032027482986450195\n",
      "\t\tEpoch time:  12.962141752243042\n",
      "Epoch 3\n",
      "\t\tClassifier train accuracy:  0.8609625668449198\n",
      "\t\tClassifier validation accuracy 0.8466198979591837\n",
      "\t\tStep time:  0.03302812576293945\n",
      "\t\tEpoch time:  13.037707328796387\n",
      "Epoch 4\n",
      "\t\tClassifier train accuracy:  0.8748185992883128\n",
      "\t\tClassifier validation accuracy 0.8670280612244898\n",
      "\t\tStep time:  0.032027244567871094\n",
      "\t\tEpoch time:  13.000174283981323\n",
      "Epoch 5\n",
      "\t\tClassifier train accuracy:  0.8867860763771545\n",
      "\t\tClassifier validation accuracy 0.8660714285714286\n",
      "\t\tStep time:  0.0320279598236084\n",
      "\t\tEpoch time:  13.181329727172852\n",
      "Epoch 6\n",
      "\t\tClassifier train accuracy:  0.9015565672027513\n",
      "\t\tClassifier validation accuracy 0.8757971938775511\n",
      "\t\tStep time:  0.03152656555175781\n",
      "\t\tEpoch time:  13.165316104888916\n",
      "Epoch 7\n",
      "\t\tClassifier train accuracy:  0.9111583802158917\n",
      "\t\tClassifier validation accuracy 0.8759566326530612\n",
      "\t\tStep time:  0.03302788734436035\n",
      "\t\tEpoch time:  13.159312009811401\n",
      "Epoch 8\n",
      "\t\tClassifier train accuracy:  0.9016957239130867\n",
      "\t\tClassifier validation accuracy 0.884406887755102\n",
      "\t\tStep time:  0.032027482986450195\n",
      "\t\tEpoch time:  13.48058795928955\n",
      "Epoch 9\n",
      "\t\tClassifier train accuracy:  0.918792119754289\n",
      "\t\tClassifier validation accuracy 0.8856823979591837\n",
      "\t\tStep time:  0.03152775764465332\n",
      "\t\tEpoch time:  13.006179809570312\n",
      "Epoch 10\n",
      "\t\tClassifier train accuracy:  0.9200047710872115\n",
      "\t\tClassifier validation accuracy 0.8874362244897959\n",
      "\t\tStep time:  0.03152751922607422\n",
      "\t\tEpoch time:  13.08674931526184\n",
      "Epoch 11\n",
      "\t\tClassifier train accuracy:  0.929566825040256\n",
      "\t\tClassifier validation accuracy 0.889030612244898\n",
      "\t\tStep time:  0.035530805587768555\n",
      "\t\tEpoch time:  13.23487663269043\n",
      "Epoch 12\n",
      "\t\tClassifier train accuracy:  0.9339204421207483\n",
      "\t\tClassifier validation accuracy 0.890625\n",
      "\t\tStep time:  0.031526803970336914\n",
      "\t\tEpoch time:  12.956137418746948\n",
      "Epoch 13\n",
      "\t\tClassifier train accuracy:  0.9375385165894679\n",
      "\t\tClassifier validation accuracy 0.8963647959183674\n",
      "\t\tStep time:  0.03603243827819824\n",
      "\t\tEpoch time:  12.691908836364746\n",
      "Epoch 14\n",
      "\t\tClassifier train accuracy:  0.9400830964356003\n",
      "\t\tClassifier validation accuracy 0.8962053571428571\n",
      "\t\tStep time:  0.03002619743347168\n",
      "\t\tEpoch time:  13.045714139938354\n",
      "INFO:tensorflow:No assets to save.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: ./savedmodel\\saved_model.pb\n",
      "\n",
      "Classifier test accuracy 0.8984375\n"
     ]
    }
   ],
   "source": [
    "from data_gen import Feature_Extraction\n",
    "from train_utils import train\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "##Data instantiation \n",
    "dataset = Feature_Extraction(minibatch_size=batch_size,proj_directory= proj_directory,real_size=real_size )\n",
    "###Train the model\n",
    "train_accuracies, valid_accuracies = train(net, dataset, epochs, batch_size, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2e166b65550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(train_accuracies, label='Train', alpha=0.5)\n",
    "plt.plot(valid_accuracies, label='Vlid', alpha=0.5)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./savedmodel\\variables\\variables\n",
      "Output node/s name : discriminator/out:0\n",
      "Prediction of the first image is : E\n"
     ]
    }
   ],
   "source": [
    "from Prediction import Run_pred\n",
    "real_size = (32,32,1)\n",
    "Run_pred(proj_directory,\"/Users/Theologis/Desktop/CAS Lab/sem-supervised_chars74k/images/tempE2.png\",real_size=real_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step we load the .pb that created in the training and run the prediction for a given image.The Output node/s name is the input in the next step without the \":0\".In the next step we must specify the output node of the NN. In the next step we are going to create the appropriate files for the DNNDK(frozen_model_dnndk.pd).We also  are going to print  all the notes of the model.\"Input_real\" is the input node and \"discriminator/out\" is the output node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create DNNDK inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./savedmodel\\variables\\variables\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint\\checkpoint.ckpt\n",
      "INFO:tensorflow:Froze 20 variables.\n",
      "INFO:tensorflow:Converted 20 variables to const ops.\n",
      "DNNDK graph successfully created\n",
      "The nodes name are:\n",
      "prefix/input_real\n",
      "prefix/discriminator/dropout/Identity\n",
      "prefix/discriminator/conv2d/kernel\n",
      "prefix/discriminator/conv2d/kernel/read\n",
      "prefix/discriminator/conv2d/bias\n",
      "prefix/discriminator/conv2d/bias/read\n",
      "prefix/discriminator/conv2d/Conv2D\n",
      "prefix/discriminator/conv2d/BiasAdd\n",
      "prefix/discriminator/mul/x\n",
      "prefix/discriminator/mul\n",
      "prefix/discriminator/Maximum\n",
      "prefix/discriminator/dropout_1/Identity\n",
      "prefix/discriminator/conv2d_1/kernel\n",
      "prefix/discriminator/conv2d_1/kernel/read\n",
      "prefix/discriminator/conv2d_1/bias\n",
      "prefix/discriminator/conv2d_1/bias/read\n",
      "prefix/discriminator/conv2d_1/Conv2D\n",
      "prefix/discriminator/conv2d_1/BiasAdd\n",
      "prefix/discriminator/mul_1/x\n",
      "prefix/discriminator/mul_1\n",
      "prefix/discriminator/Maximum_1\n",
      "prefix/discriminator/conv2d_2/kernel\n",
      "prefix/discriminator/conv2d_2/kernel/read\n",
      "prefix/discriminator/conv2d_2/bias\n",
      "prefix/discriminator/conv2d_2/bias/read\n",
      "prefix/discriminator/conv2d_2/Conv2D\n",
      "prefix/discriminator/conv2d_2/BiasAdd\n",
      "prefix/discriminator/batch_normalization_1/gamma\n",
      "prefix/discriminator/batch_normalization_1/gamma/read\n",
      "prefix/discriminator/batch_normalization_1/beta\n",
      "prefix/discriminator/batch_normalization_1/beta/read\n",
      "prefix/discriminator/batch_normalization_1/Const\n",
      "prefix/discriminator/batch_normalization_1/Const_1\n",
      "prefix/discriminator/batch_normalization_1/FusedBatchNorm\n",
      "prefix/discriminator/mul_2/x\n",
      "prefix/discriminator/mul_2\n",
      "prefix/discriminator/Maximum_2\n",
      "prefix/discriminator/dropout_2/Identity\n",
      "prefix/discriminator/conv2d_3/kernel\n",
      "prefix/discriminator/conv2d_3/kernel/read\n",
      "prefix/discriminator/conv2d_3/bias\n",
      "prefix/discriminator/conv2d_3/bias/read\n",
      "prefix/discriminator/conv2d_3/Conv2D\n",
      "prefix/discriminator/conv2d_3/BiasAdd\n",
      "prefix/discriminator/batch_normalization_2/gamma\n",
      "prefix/discriminator/batch_normalization_2/gamma/read\n",
      "prefix/discriminator/batch_normalization_2/beta\n",
      "prefix/discriminator/batch_normalization_2/beta/read\n",
      "prefix/discriminator/batch_normalization_2/Const\n",
      "prefix/discriminator/batch_normalization_2/Const_1\n",
      "prefix/discriminator/batch_normalization_2/FusedBatchNorm\n",
      "prefix/discriminator/mul_3/x\n",
      "prefix/discriminator/mul_3\n",
      "prefix/discriminator/Maximum_3\n",
      "prefix/discriminator/conv2d_4/kernel\n",
      "prefix/discriminator/conv2d_4/kernel/read\n",
      "prefix/discriminator/conv2d_4/bias\n",
      "prefix/discriminator/conv2d_4/bias/read\n",
      "prefix/discriminator/conv2d_4/Conv2D\n",
      "prefix/discriminator/conv2d_4/BiasAdd\n",
      "prefix/discriminator/batch_normalization_3/gamma\n",
      "prefix/discriminator/batch_normalization_3/gamma/read\n",
      "prefix/discriminator/batch_normalization_3/beta\n",
      "prefix/discriminator/batch_normalization_3/beta/read\n",
      "prefix/discriminator/batch_normalization_3/Const\n",
      "prefix/discriminator/batch_normalization_3/Const_1\n",
      "prefix/discriminator/batch_normalization_3/FusedBatchNorm\n",
      "prefix/discriminator/mul_4/x\n",
      "prefix/discriminator/mul_4\n",
      "prefix/discriminator/Maximum_4\n",
      "prefix/discriminator/conv2d_5/kernel\n",
      "prefix/discriminator/conv2d_5/kernel/read\n",
      "prefix/discriminator/conv2d_5/bias\n",
      "prefix/discriminator/conv2d_5/bias/read\n",
      "prefix/discriminator/conv2d_5/Conv2D\n",
      "prefix/discriminator/conv2d_5/BiasAdd\n",
      "prefix/discriminator/mul_5/x\n",
      "prefix/discriminator/mul_5\n",
      "prefix/discriminator/Maximum_5\n",
      "prefix/discriminator/Mean/reduction_indices\n",
      "prefix/discriminator/Mean\n",
      "prefix/discriminator/dense/kernel\n",
      "prefix/discriminator/dense/kernel/read\n",
      "prefix/discriminator/dense/bias\n",
      "prefix/discriminator/dense/bias/read\n",
      "prefix/discriminator/dense/MatMul\n",
      "prefix/discriminator/dense/BiasAdd\n",
      "prefix/discriminator/out\n"
     ]
    }
   ],
   "source": [
    "from Create_DNNDK_files import Create_Frozen_graph\n",
    "Create_Frozen_graph(output_node_names=\"discriminator/out\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run DECENT_Q\n",
    "A script file named **“decen_q.sh”** can be found in ${dnndk_chars74k}/,\n",
    "shown as below. Run “sh decent_q.sh” to invoke the DECENT_Q tool to perform quantization with the\n",
    "appropriate parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decent_q quantize \\\n",
    "  --input_graph_def frozen_model_dnndk.pb \\\n",
    "  --input_nodes  input_real\\\n",
    "  --input_shapes ?,32,32,1 \\\n",
    "  --output_nodes discriminator/out \\\n",
    "  --input_fn data_den.load_data\\\n",
    "  --method 1 \\\n",
    "  --gpu 0 \\\n",
    "  --calib_iter 10 \\\n",
    "  --output_dir ./quantize_results \\ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-dnndk-1.12",
   "language": "python",
   "name": "tf-dnndk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
